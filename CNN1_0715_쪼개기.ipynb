{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP06zF87IUywQ4KoYFtdItq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiyeonjin/0624_new/blob/main/CNN1_0715_%EC%AA%BC%EA%B0%9C%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CNN 모델 전체 구조\n",
        "\n",
        "ReLu 개념 정리\n",
        "\n",
        "| 항목        | 내용                                                         |\n",
        "| --------- | ---------------------------------------------------------- |\n",
        "| **역할**    | 인공신경망의 은닉층(중간 계산 단계)에서 사용되는 **활성화 함수**                     |\n",
        "| **수식**    | ReLU(x) = max(0, x)                                        |\n",
        "| **작동 방식** | 입력값이 0보다 크면 그대로 출력, 작으면 0으로 바꿈                             |\n",
        "| **예시**    | - ReLU(3) → 3<br>- ReLU(-2) → 0                            |\n",
        "| **특징**    | - 연산이 간단해서 속도 빠름<br>- 음수 제거로 학습 효율 향상<br>- 기울기 소실 문제 일부 해결 |\n",
        "| **사용 위치** | 은닉층 (중간층)                                                  |\n",
        "\n",
        "Softmax 정리\n",
        "\n",
        "| 항목        | 내용                                              |\n",
        "| --------- | ----------------------------------------------- |\n",
        "| **역할**    | 인공신경망의 출력층에서 사용되는 **정규화 함수(확률화)**               |\n",
        "| **수식**    | Softmax(zᵢ) = exp(zᵢ) / Σ exp(zⱼ)               |\n",
        "| **작동 방식** | 여러 숫자를 받아서 **0\\~1 사이의 값으로 변환**, 전체 합이 1이 되도록 만듦 |\n",
        "| **예시**    | 입력: \\[2.0, 1.0, 0.1] → 출력: \\[0.65, 0.24, 0.11]  |\n",
        "| **특징**    | - 출력값을 확률처럼 해석 가능<br>- 가장 높은 값이 예측 결과로 선택됨      |\n",
        "| **사용 위치** | 출력층 (마지막층, 분류 문제에서 사용)                          |\n"
      ],
      "metadata": {
        "id": "vy7-39KReMtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.keras.layers.Dense(128, activation='relu')가 의미하는 것**\n",
        "\n",
        "완전 연결(Dense) 신경망 레이어를 하나 추가하는 코드이다.\n",
        "\n",
        "1. 이전 레이어에서 전달받은 입력값들(벡터 형태)을 가지고\n",
        "\n",
        "2. 각각의 입력에 가중치를 곱하고 더한 후 (선형 조합)\n",
        "\n",
        "3. 그 결과에 ReLU 함수를 적용해서 출력값을 만들어냄\n",
        "-> 즉, max(0, x) 연산이 일어남.\n",
        "\n",
        " -----------------------------------------\n",
        "ReLU를 쓰는 이유\n",
        "\n",
        "1. ReLU는 0보다 크면 통과, 작으면 0으로 자름.\n",
        "\n",
        "2. 딥러닝에서 가장 널리 쓰이는 빠르고 효과적인 활성화 함수\n",
        "\n",
        "3. 음수값을 제거해서 비선형성 확보 + 기울기 소실 문제 방지에 도움됨"
      ],
      "metadata": {
        "id": "p4eQ2wlWkocH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 분석\n",
        "\n",
        "tf.keras.Sequential([...])\n",
        "→ 레이어를 순차적으로 쌓는 CNN 모델 구성\n",
        "\n",
        "Conv2D(16, (3, 3), activation='relu', input_shape=(64, 64, 3))\n",
        "→ 첫 번째 합성곱 레이어: 3x3 필터 16개, 입력은 64x64 RGB 이미지\n",
        "\n",
        "MaxPooling2D(2, 2)\n",
        "→ 특징 맵 크기 절반 축소, 정보 요약\n",
        "\n",
        "Conv2D(32, (3, 3), activation='relu')\n",
        "→ 두 번째 합성곱 레이어: 더 많은 필터로 복잡한 특징 추출\n",
        "\n",
        "Conv2D(64, (3, 3), activation='relu')\n",
        "→ 세 번째 합성곱 레이어: 고차원 특징 추출\n",
        "\n",
        "Flatten()\n",
        "→ 2D 출력 → 1D 벡터로 변환 (Dense 레이어 연결 준비)\n",
        "\n",
        "Dense(128, activation='relu')\n",
        "→ 완전 연결층, 뉴런 128개, 비선형성 추가\n",
        "\n",
        "Dropout(0.5)\n",
        "→ 학습 중 50% 뉴런 무작위 제거, 과적합 방지\n",
        "\n",
        "Dense(3, activation='softmax')\n",
        "→ 출력층, 클래스 3개 확률로 예측\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "→ 모델 학습 준비: 손실 함수, 최적화 방법, 정확도 측정 설정\n",
        "\n"
      ],
      "metadata": {
        "id": "pt3YpBKRwdf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_simple_cnn():\n",
        "    \"\"\"\n",
        "    교육용 간단한 CNN 모델 생성\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        # 첫 번째 컨볼루션 레이어\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # 두 번째 컨볼루션 레이어\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # 세 번째 컨볼루션 레이어\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # Flatten & Dense 레이어\n",
        "        tf.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(3, activation='softmax')  # 3 classes: Animal/Car/Other\n",
        "    ])\n",
        "\n",
        "    # 모델 컴파일\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"🧠 CNN 모델 생성 완료!\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "s_n64_kdpPaL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4gYj0RTJwgRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 CNN 구조 시각화\n",
        "def visualize_model_architecture(model):\n",
        "    \"\"\"\n",
        "    CNN 모델 구조를 시각적으로 보여주기\n",
        "    \"\"\"\n",
        "    print(\"\\n📋 CNN 모델 구조:\")\n",
        "    print(\"=\" * 50)\n",
        "    model.summary()\n",
        "\n",
        "    # 레이어별 설명\n",
        "    print(\"\\n🔍 레이어별 역할:\")\n",
        "    print(\"📌 Conv2D: 특징 추출 (엣지, 패턴 등)\")\n",
        "    print(\"📌 MaxPooling2D: 크기 축소 + 중요 특징 선택\")\n",
        "    print(\"📌 Flatten: 2D → 1D 변환\")\n",
        "    print(\"📌 Dense: 최종 분류 결정\")\n",
        "    print(\"📌 Dropout: 과적합 방지\")"
      ],
      "metadata": {
        "id": "U4gtEx3tpXaO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎲 가짜 데이터로 빠른 훈련\n",
        "def quick_train_with_dummy_data(model):\n",
        "    \"\"\"\n",
        "    데모용 가짜 데이터로 빠른 훈련\n",
        "    \"\"\"\n",
        "    print(\"\\n🎓 데모용 빠른 훈련 시작...\")\n",
        "\n",
        "    # 가짜 훈련 데이터 생성 (200개 샘플)\n",
        "    X_train = np.random.rand(200, 64, 64, 3).astype('float32')\n",
        "    y_train = tf.keras.utils.to_categorical(np.random.randint(0, 3, 200), 3)\n",
        "\n",
        "    # 빠른 훈련 (3 epochs만)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=3,\n",
        "        batch_size=32,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"✅ 훈련 완료! (실제 프로젝트에서는 실제 데이터 사용)\")\n",
        "    return history"
      ],
      "metadata": {
        "id": "ju8HdI_xpZgN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔍 CNN 필터 시각화\n",
        "def visualize_cnn_filters(model):\n",
        "    \"\"\"\n",
        "    CNN 첫 번째 레이어의 학습된 필터들 시각화\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 모델이 빌드되었는지 확인\n",
        "        if not hasattr(model, 'built') or not model.built:\n",
        "            print(\"⚠️ 모델을 빌드하는 중...\")\n",
        "            dummy_input = np.random.rand(1, 64, 64, 3)\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "        # 첫 번째 Conv2D 레이어 찾기\n",
        "        first_conv_layer = None\n",
        "        for layer in model.layers:\n",
        "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "                first_conv_layer = layer\n",
        "                break\n",
        "\n",
        "        if first_conv_layer is None:\n",
        "            print(\"❌ Conv2D 레이어를 찾을 수 없습니다.\")\n",
        "            return\n",
        "\n",
        "        # 첫 번째 Conv2D 레이어의 가중치 추출\n",
        "        weights = first_conv_layer.get_weights()\n",
        "        if len(weights) == 0:\n",
        "            print(\"⚠️ 아직 가중치가 초기화되지 않았습니다.\")\n",
        "            return\n",
        "\n",
        "        filters = weights[0]  # 필터 가중치\n",
        "\n",
        "        print(f\"\\n🔍 첫 번째 레이어 필터 시각화\")\n",
        "        print(f\"필터 개수: {filters.shape[3]}개\")\n",
        "        print(f\"필터 크기: {filters.shape[0]}x{filters.shape[1]}\")\n",
        "\n",
        "        # 필터 중 처음 8개만 시각화\n",
        "        num_filters_to_show = min(8, filters.shape[3])\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "        fig.suptitle('CNN Learned Filters (First Layer)', fontsize=16)\n",
        "\n",
        "        for i in range(num_filters_to_show):\n",
        "            ax = axes[i // 4, i % 4]\n",
        "\n",
        "            # 필터를 시각화하기 위해 정규화\n",
        "            filter_img = filters[:, :, 0, i]  # 첫 번째 채널의 i번째 필터\n",
        "\n",
        "            # 정규화 (0-1 범위로)\n",
        "            if filter_img.max() > filter_img.min():\n",
        "                filter_img = (filter_img - filter_img.min()) / (filter_img.max() - filter_img.min())\n",
        "\n",
        "            ax.imshow(filter_img, cmap='viridis')\n",
        "            ax.set_title(f'Filter {i+1}')\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 필터 시각화 중 오류 발생: {str(e)}\")\n",
        "        print(\"💡 이는 모델 구조나 가중치 이슈일 수 있습니다.\")\n",
        "        print(\"📝 주요 기능(예측)은 정상 작동합니다!\")"
      ],
      "metadata": {
        "id": "_a2O4-V9pbYX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📸 이미지 업로드 및 전처리\n",
        "def upload_and_preprocess_image():\n",
        "    \"\"\"\n",
        "    이미지 업로드 및 CNN 입력용 전처리\n",
        "    \"\"\"\n",
        "    print(\"📸 이미지를 업로드해주세요!\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    image_data = uploaded[filename]\n",
        "\n",
        "    # 이미지 로드 및 전처리\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    # RGB로 변환 (RGBA인 경우)\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "    # 크기 조정 (64x64)\n",
        "    image_resized = image.resize((64, 64))\n",
        "\n",
        "    # 배열로 변환 및 정규화\n",
        "    image_array = np.array(image_resized).astype('float32') / 255.0\n",
        "\n",
        "    # 배치 차원 추가 (1, 64, 64, 3)\n",
        "    image_batch = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "    return image, image_resized, image_batch, filename"
      ],
      "metadata": {
        "id": "QxpHh4Vipdu9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎯 CNN 예측 및 결과 시각화\n",
        "def predict_and_visualize(model, original_img, processed_img, image_batch, filename):\n",
        "    \"\"\"\n",
        "    CNN으로 예측하고 결과 시각화\n",
        "    \"\"\"\n",
        "    # 클래스 라벨 정의\n",
        "    class_names = ['Animal', 'Car', 'Other']\n",
        "\n",
        "    # CNN 예측\n",
        "    predictions = model.predict(image_batch, verbose=0)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_class]\n",
        "\n",
        "    # 결과 시각화\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # 원본 이미지\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(original_img)\n",
        "    plt.title(f'original image\\n({filename})')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 전처리된 이미지 (CNN 입력)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(processed_img)\n",
        "    plt.title('CNN input image\\n(64x64 크기 조정)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 예측 결과\n",
        "    plt.subplot(1, 3, 3)\n",
        "    bars = plt.bar(class_names, predictions[0])\n",
        "    bars[predicted_class].set_color('red')  # 최고 확률 클래스 강조\n",
        "    plt.title(f'CNN Prediction Results\\nPrediction: {class_names[predicted_class]} ({confidence:.2%})')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "    # 확률 값 표시\n",
        "    for i, (name, prob) in enumerate(zip(class_names, predictions[0])):\n",
        "        plt.text(i, prob + 0.02, f'{prob:.2%}', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 결과 출력\n",
        "    print(\"\\n🎯 CNN Prediction Results:\")\n",
        "    print(\"=\" * 30)\n",
        "    for i, (name, prob) in enumerate(zip(class_names, predictions[0])):\n",
        "        marker = \"👉\" if i == predicted_class else \"  \"\n",
        "        print(f\"{marker} {name}: {prob:.2%}\")\n",
        "    print(\"=\" * 30)\n",
        "    print(f\"Final Prediction: {class_names[predicted_class]} (Confidence: {confidence:.2%})\")\n"
      ],
      "metadata": {
        "id": "wqT4SqB9pkLd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔬 CNN 중간 레이어 활성화 시각화\n",
        "def visualize_intermediate_activations(model, image_batch):\n",
        "    \"\"\"\n",
        "    CNN 중간 레이어들의 활성화 맵 시각화\n",
        "    \"\"\"\n",
        "    print(\"\\n🔬 CNN 내부 작동 과정 시각화...\")\n",
        "\n",
        "    try:\n",
        "        # 모델이 빌드되었는지 확인\n",
        "        if not hasattr(model, 'built') or not model.built:\n",
        "            print(\"⚠️ 모델을 빌드하는 중...\")\n",
        "            # 더미 데이터로 모델 빌드\n",
        "            dummy_input = np.random.rand(1, 64, 64, 3)\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "        # Conv2D 레이어만 찾기\n",
        "        conv_layers = []\n",
        "        layer_names = []\n",
        "\n",
        "        for i, layer in enumerate(model.layers):\n",
        "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "                conv_layers.append(layer)\n",
        "                layer_names.append(f'Conv2D Layer {len(conv_layers)}')\n",
        "\n",
        "        if len(conv_layers) == 0:\n",
        "            print(\"❌ Conv2D 레이어를 찾을 수 없습니다.\")\n",
        "            return\n",
        "\n",
        "        # 중간 레이어 출력을 위한 모델 생성\n",
        "        layer_outputs = [layer.output for layer in conv_layers]\n",
        "        activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "        # 활성화 맵 계산\n",
        "        activations = activation_model.predict(image_batch, verbose=0)\n",
        "\n",
        "        # 단일 출력인 경우 리스트로 변환\n",
        "        if not isinstance(activations, list):\n",
        "            activations = [activations]\n",
        "\n",
        "        # 시각화\n",
        "        num_layers = min(3, len(conv_layers))  # 최대 3개 레이어만\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            activation = activations[i]\n",
        "            layer_name = layer_names[i]\n",
        "\n",
        "            # 처음 4개 필터만 표시\n",
        "            num_filters = min(4, activation.shape[-1])\n",
        "            for j in range(num_filters):\n",
        "                plt.subplot(num_layers, 4, i*4 + j + 1)\n",
        "\n",
        "                # 활성화 맵 정규화\n",
        "                feature_map = activation[0, :, :, j]\n",
        "                if feature_map.max() > feature_map.min():\n",
        "                    feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())\n",
        "\n",
        "                plt.imshow(feature_map, cmap='viridis')\n",
        "                plt.title(f'{layer_name}\\nFilter {j+1}')\n",
        "                plt.axis('off')\n",
        "\n",
        "        plt.suptitle('CNN Feature Maps - How CNN \"Sees\" Your Image', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"💡 해석:\")\n",
        "        print(\"- 첫 번째 레이어: 기본적인 엣지, 색상 검출\")\n",
        "        print(\"- 두 번째 레이어: 더 복잡한 패턴 조합\")\n",
        "        print(\"- 세 번째 레이어: 고수준 특징 (객체 부분)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 활성화 시각화 중 오류 발생: {str(e)}\")\n",
        "        print(\"💡 이는 모델 구조나 TensorFlow 버전 이슈일 수 있습니다.\")\n",
        "        print(\"📝 주요 기능(예측)은 정상 작동합니다!\")"
      ],
      "metadata": {
        "id": "50kL0_-EpqHU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎮 메인 실행 함수\n",
        "def run_cnn_demo():\n",
        "    \"\"\"\n",
        "    CNN 교육용 데모 메인 실행\n",
        "    \"\"\"\n",
        "    print(\"🎉 진짜 CNN 교육용 데모 시작!\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 1. CNN 모델 생성\n",
        "    model = create_simple_cnn()\n",
        "\n",
        "    # 2. 모델 구조 확인\n",
        "    visualize_model_architecture(model)\n",
        "\n",
        "    # 3. 빠른 훈련 (데모용)\n",
        "    history = quick_train_with_dummy_data(model)\n",
        "\n",
        "    # 4. 학습된 필터 시각화\n",
        "    visualize_cnn_filters(model)\n",
        "\n",
        "    # 5. 이미지 업로드 및 예측\n",
        "    original_img, processed_img, image_batch, filename = upload_and_preprocess_image()\n",
        "\n",
        "    # 6. CNN 예측 및 결과 시각화\n",
        "    predict_and_visualize(model, original_img, processed_img, image_batch, filename)\n",
        "\n",
        "    # 7. CNN 내부 작동 과정 시각화\n",
        "    visualize_intermediate_activations(model, image_batch)\n",
        "\n",
        "    print(\"\\n🎓 CNN 데모 완료!\")\n",
        "    print(\"💡 이제 CNN이 어떻게 이미지를 '이해'하는지 보셨습니다!\")\n",
        "\n",
        "# 🚀 데모 실행\n",
        "print(\"📚 CNN 교육용 데모 - 실제 신경망으로 이미지 분류 체험\")\n",
        "print(\"🔥 이번에는 진짜 CNN입니다!\")\n",
        "print()\n",
        "run_cnn_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "IftFGzjEpsEF",
        "outputId": "62ccbb78-eb76-4dae-c4e3-bc1ab6ebbd22"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📚 CNN 교육용 데모 - 실제 신경망으로 이미지 분류 체험\n",
            "🔥 이번에는 진짜 CNN입니다!\n",
            "\n",
            "🎉 진짜 CNN 교육용 데모 시작!\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-17-1975667347.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔥 이번에는 진짜 CNN입니다!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mrun_cnn_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-17-1975667347.py\u001b[0m in \u001b[0;36mrun_cnn_demo\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 1. CNN 모델 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_simple_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# 2. 모델 구조 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-10-1063675605.py\u001b[0m in \u001b[0;36mcreate_simple_cnn\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0m교육용\u001b[0m \u001b[0m간단한\u001b[0m \u001b[0mCNN\u001b[0m \u001b[0m모델\u001b[0m \u001b[0m생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m     model = tf.keras.Sequential([\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# 첫 번째 컨볼루션 레이어\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    }
  ]
}