# ğŸ¯ ë¹„ë””ì˜¤ ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹ ì•™ìƒë¸” ê°ì²´ íƒì§€ê¸° (YOLOv8 + Ensemble)

> Google Colab ê¸°ë°˜ ì‹¤í–‰ | YOLOv8n + Confidence Threshold Ensemble | ê°ì²´ íƒì§€ + ë¶„ì„ ë¦¬í¬íŠ¸ ìë™ ìƒì„±

---

## ì•™ìƒë¸” ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ YOLOv8 ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ê³ , **ì—¬ëŸ¬ confidence thresholdë¥¼ ì•™ìƒë¸”**í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ íƒì§€ ì„±ëŠ¥ì„ ê°œì„ í•©ë‹ˆë‹¤.

### âœ… ì£¼ìš” ê¸°ëŠ¥
- **YOLOv8n** ëª¨ë¸ ê¸°ë°˜ íƒì§€
- **ë‹¤ì¤‘ threshold ì•™ìƒë¸”**
- **ê°€ì¤‘ì¹˜ ê¸°ë°˜ Non-Maximum Suppression (NMS)**
- **íƒì§€ ê²°ê³¼ ì˜ìƒ + ë¶„ì„ ë¦¬í¬íŠ¸ ìë™ ìƒì„±**
- **Google Colabì—ì„œ ì½”ë“œ 1íšŒ ì‹¤í–‰ìœ¼ë¡œ ì „ ê³¼ì • ìë™í™”**

---

## ë¨¸ì‹ ëŸ¬ë‹ ì•™ìƒë¸”ì´ë€?

ì•™ìƒë¸”(Ensemble)ì€ ì—¬ëŸ¬ ëª¨ë¸(ë˜ëŠ” ì˜ˆì¸¡)ì„ ê²°í•©í•´ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.  
ì´ í”„ë¡œì íŠ¸ëŠ” YOLOv8 ëª¨ë¸ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ë˜, **ì—¬ëŸ¬ ê°€ì§€ confidence threshold ì„¤ì •**ì„ í†µí•´ ë‹¤ì–‘í•œ íƒì§€ ê²°ê³¼ë¥¼ ì–»ê³ , ì´ë¥¼ **ê°€ì¤‘ í‰ê·  ë°©ì‹ìœ¼ë¡œ í†µí•©**í•˜ì—¬ **ë” ì•ˆì •ì ì´ê³  ëˆ„ë½ì´ ì ì€ íƒì§€**ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

---

## âš™ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰ ë°©ë²• (Google Colab)

1. ì•„ë˜ ì „ì²´ ì½”ë“œë¥¼ Google Colabì— ë³µì‚¬
2. `Run`ìœ¼ë¡œ ì‹¤í–‰
3. ë¹„ë””ì˜¤ ì—…ë¡œë“œ â†’ íƒì§€ ê²°ê³¼ ë¶„ì„ â†’ ZIP ìë™ ë‹¤ìš´ë¡œë“œ

---

## ì „ì²´ ì½”ë“œ (ë³µë¶™ ì‹¤í–‰)

```python
# ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•¨ìˆ˜
import subprocess
import sys
import os

def install_packages():
    packages = ['ultralytics', 'opencv-python', 'numpy', 'matplotlib']
    for package in packages:
        try:
            if package == 'opencv-python':
                import cv2
            elif package == 'ultralytics':
                from ultralytics import YOLO
            else:
                __import__(package)
            print(f"âœ… {package} ì„¤ì¹˜ë¨")
        except ImportError:
            print(f"ğŸ“¦ {package} ì„¤ì¹˜ ì¤‘...")
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '--quiet'])

install_packages()

# ğŸ§  ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import cv2
import numpy as np
from collections import defaultdict
import zipfile
import warnings
warnings.filterwarnings('ignore')

from ultralytics import YOLO
from google.colab import files
import matplotlib.pyplot as plt
from IPython.display import display, HTML

print("âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ!")

# ğŸ¤– ê°ì²´ íƒì§€ í´ë˜ìŠ¤ ì •ì˜
class VideoEnsembleDetector:
    def __init__(self):
        print("ğŸ¤– ì•™ìƒë¸” ëª¨ë¸ ë¡œë”© ì¤‘...")
        try:
            self.model = YOLO('yolov8n.pt')
            print("âœ… YOLOv8n ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            self.ensemble_configs = [
                {'conf': 0.15, 'weight': 0.2},
                {'conf': 0.25, 'weight': 0.3},
                {'conf': 0.35, 'weight': 0.3},
                {'conf': 0.45, 'weight': 0.2}
            ]
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return

        self.target_classes = {
            'person': 0, 'bicycle': 1, 'car': 2, 'motorcycle': 3,
            'bus': 5, 'truck': 7, 'traffic light': 9, 'stop sign': 11
        }
        self.colors = {
            'person': (0, 255, 0), 'bicycle': (255, 0, 0), 'car': (0, 0, 255),
            'motorcycle': (255, 255, 0), 'bus': (128, 0, 128),
            'truck': (255, 165, 0), 'traffic light': (0, 255, 255),
            'stop sign': (255, 0, 255)
        }
        self.iou_threshold = 0.5
        print("ğŸ¯ ì•™ìƒë¸” íƒì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ!")

    def upload_video(self):
        print("ğŸ“ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”...")
        uploaded = files.upload()
        if not uploaded:
            return None, None
        filename = list(uploaded.keys())[0]
        return filename, filename.split('.')[0]

    def ensemble_predict(self, frame):
        all_detections = []
        for config in self.ensemble_configs:
            try:
                results = self.model(frame, conf=config['conf'], verbose=False)
                weight = config['weight']
                for result in results:
                    if result.boxes is not None:
                        for box in result.boxes:
                            cls_id = int(box.cls[0])
                            conf = float(box.conf[0]) * weight
                            bbox = box.xyxy[0].cpu().numpy()
                            all_detections.append({
                                'bbox': bbox,
                                'conf': conf,
                                'cls_id': cls_id,
                                'threshold': config['conf']
                            })
            except Exception:
                continue
        return all_detections

    def weighted_nms(self, detections):
        if not detections:
            return []
        class_detections = defaultdict(list)
        for det in detections:
            class_detections[det['cls_id']].append(det)
        final_detections = []
        for cls_id, cls_dets in class_detections.items():
            cls_dets.sort(key=lambda x: x['conf'], reverse=True)
            kept = []
            for det in cls_dets:
                bbox1 = det['bbox']
                if all(self.calculate_iou(bbox1, k['bbox']) <= self.iou_threshold for k in kept):
                    kept.append(det)
                    if len(kept) >= 15:
                        break
            final_detections.extend(kept)
        return final_detections

    def calculate_iou(self, bbox1, bbox2):
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        xi1, yi1 = max(x1_1, x1_2), max(y1_1, y1_2)
        xi2, yi2 = min(x2_1, x2_2), min(y2_1, y2_2)
        if xi2 <= xi1 or yi2 <= yi1:
            return 0.0
        inter = (xi2 - xi1) * (yi2 - yi1)
        union = (x2_1 - x1_1) * (y2_1 - y1_1) + (x2_2 - x1_2) * (y2_2 - y1_2) - inter
        return inter / union if union > 0 else 0.0

    def draw_detections(self, frame, detections):
        class_names = self.model.names
        for det in detections:
            bbox, conf, cls_id = det['bbox'], det['conf'], det['cls_id']
            class_name = class_names.get(cls_id, 'unknown')
            if class_name not in self.target_classes:
                continue
            x1, y1, x2, y2 = map(int, bbox)
            color = self.colors.get(class_name, (255, 255, 255))
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            label = f"{class_name}: {conf:.2f}"
            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
            cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w, y1), color, -1)
            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        return frame

    def process_video(self, video_path, max_frames=900):
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return None, {}
        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        process_frames = min(total_frames, max_frames)
        output_path = "ensemble_detected_video.mp4"
        out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))
        frame_count = 0
        detection_stats = defaultdict(int)
        while frame_count < process_frames:
            ret, frame = cap.read()
            if not ret:
                break
            frame_count += 1
            detections = self.ensemble_predict(frame)
            filtered = self.weighted_nms(detections)
            for det in filtered:
                class_name = self.model.names.get(det['cls_id'], 'unknown')
                if class_name in self.target_classes:
                    detection_stats[class_name] += 1
            result_frame = self.draw_detections(frame.copy(), filtered)
            out.write(result_frame)
        cap.release()
        out.release()
        return output_path, detection_stats

    def create_final_package(self, video_path, stats, title):
        stats_file = "ensemble_detection_report.txt"
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write("ì•™ìƒë¸” ê°ì²´ íƒì§€ ê²°ê³¼ ë¦¬í¬íŠ¸\n\n")
            f.write(f"ë¹„ë””ì˜¤ íŒŒì¼: {title}\n")
            f.write(f"ì‚¬ìš© ëª¨ë¸: YOLOv8n\n")
            f.write(f"Threshold: {[c['conf'] for c in self.ensemble_configs]}\n")
            f.write("\níƒì§€ ê²°ê³¼:\n")
            total = sum(stats.values())
            for k, v in sorted(stats.items(), key=lambda x: x[1], reverse=True):
                pct = (v / total * 100) if total > 0 else 0
                f.write(f"{k:15}: {v:4d}íšŒ ({pct:5.1f}%)\n")
        zip_filename = f"{title}_ensemble_detection.zip"
        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
            if os.path.exists(video_path):
                zipf.write(video_path, "ensemble_detected_video.mp4")
            zipf.write(stats_file, "detection_report.txt")
        os.remove(stats_file)
        return zip_filename

    def run_detection(self):
        print("ğŸ¯ ë¹„ë””ì˜¤ ì•™ìƒë¸” íƒì§€ ì‹œì‘!")
        video_path, title = self.upload_video()
        if not video_path:
            return
        output_video, stats = self.process_video(video_path)
        if not output_video:
            return
        print(f"ğŸ“Š ì´ íƒì§€ íšŸìˆ˜: {sum(stats.values())}íšŒ")
        zip_file = self.create_final_package(output_video, stats, title)
        print(f"ğŸ“¦ ê²°ê³¼ íŒ¨í‚¤ì§€: {zip_file}")
        files.download(zip_file)

# â–¶ï¸ ì‹¤í–‰
detector = VideoEnsembleDetector()
detector.run_detection()
```
## ê²°ê³¼
<img width="1052" height="590" alt="image" src="https://github.com/user-attachments/assets/3cff8944-d8ae-4a3f-8d7d-8bc8ca48bf54" />
<img width="1066" height="494" alt="image" src="https://github.com/user-attachments/assets/aa1c49db-1ec2-4e0e-8c41-c58ad065bdc2" />

