# ğŸ¯ ë¹„ë””ì˜¤ ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹ ì•™ìƒë¸” ê°ì²´ íƒì§€ê¸° (YOLOv8 + Ensemble)

> Google Colab ê¸°ë°˜ ì‹¤í–‰ | YOLOv8n + Confidence Threshold Ensemble | ê°ì²´ íƒì§€ + ë¶„ì„ ë¦¬í¬íŠ¸ ìë™ ìƒì„±


## ì•™ìƒë¸” ê°ì²´ íƒì§€ë€?

ì´ í”„ë¡œì íŠ¸ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ YOLOv8 ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ê³ , **ì—¬ëŸ¬ confidence thresholdë¥¼ ì•™ìƒë¸”**í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ íƒì§€ ì„±ëŠ¥ì„ ê°œì„ í•©ë‹ˆë‹¤.

ì•™ìƒë¸”(Ensemble)ì€ ì—¬ëŸ¬ ê°œì˜ ëª¨ë¸ ì˜ˆì¸¡ì„ ê²°í•©í•´ ìµœì¢… ê²°ê³¼ë¥¼ ë„ì¶œí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ë³¸ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ëœ ë°©ì‹ì€:

- ë‹¤ìˆ˜ì˜ YOLOv8 ëª¨ë¸ì„ ì„œë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜(.pt) íŒŒì¼ë¡œ ë¶ˆëŸ¬ì™€ ê°™ì€ ì˜ìƒì„ ë¶„ì„

- ê° ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ Weighted Non-Maximum Suppression (NMS) ë°©ì‹ìœ¼ë¡œ í†µí•©í•˜ì—¬ ì¤‘ë³µ ì œê±°

- ì•™ìƒë¸” íš¨ê³¼ë¡œ ì¸í•´ ê°ì²´ íƒì§€ì˜ ì •í™•ë„, ì‹ ë¢°ë„, ì¼ê´€ì„± í–¥ìƒ

ğŸ“Œ Weighted NMSë€?

ì—¬ëŸ¬ ëª¨ë¸ì´ íƒì§€í•œ ë°•ìŠ¤ ì¤‘ ìœ„ì¹˜ê°€ ë¹„ìŠ·í•œ ê²ƒë“¤ë¼ë¦¬ í‰ê· ì„ ë‚´ì–´ ë” ì •í™•í•œ ìµœì¢… ë°•ìŠ¤ë¥¼ ìƒì„±

### âœ… ì£¼ìš” ê¸°ëŠ¥
- **YOLOv8n** ëª¨ë¸ ê¸°ë°˜ íƒì§€
- **ë‹¤ì¤‘ threshold ì•™ìƒë¸”**
- **ê°€ì¤‘ì¹˜ ê¸°ë°˜ Non-Maximum Suppression (NMS)**
- **íƒì§€ ê²°ê³¼ ì˜ìƒ + ë¶„ì„ ë¦¬í¬íŠ¸ ìë™ ìƒì„±**
- **Google Colabì—ì„œ ì½”ë“œ 1íšŒ ì‹¤í–‰ìœ¼ë¡œ ì „ ê³¼ì • ìë™í™”**

---

## ë¨¸ì‹ ëŸ¬ë‹ ì•™ìƒë¸”ì´ë€?

ì•™ìƒë¸”(Ensemble)ì€ ì—¬ëŸ¬ ëª¨ë¸(ë˜ëŠ” ì˜ˆì¸¡)ì„ ê²°í•©í•´ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.  
ì´ í”„ë¡œì íŠ¸ëŠ” YOLOv8 ëª¨ë¸ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ë˜, **ì—¬ëŸ¬ ê°€ì§€ confidence threshold ì„¤ì •**ì„ í†µí•´ ë‹¤ì–‘í•œ íƒì§€ ê²°ê³¼ë¥¼ ì–»ê³ , ì´ë¥¼ **ê°€ì¤‘ í‰ê·  ë°©ì‹ìœ¼ë¡œ í†µí•©**í•˜ì—¬ **ë” ì•ˆì •ì ì´ê³  ëˆ„ë½ì´ ì ì€ íƒì§€**ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

---

## âš™ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰ ë°©ë²• (Google Colab)

1. ì•„ë˜ ì „ì²´ ì½”ë“œë¥¼ Google Colabì— ë³µì‚¬
2. `Run`ìœ¼ë¡œ ì‹¤í–‰
3. ë¹„ë””ì˜¤ ì—…ë¡œë“œ â†’ íƒì§€ ê²°ê³¼ ë¶„ì„ â†’ ZIP ìë™ ë‹¤ìš´ë¡œë“œ

---

## í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
```
!pip install ultralytics opencv-python numpy matplotlib
```

## ì „ì²´ ì½”ë“œ (ë³µë¶™ ì‹¤í–‰)

```python
# ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  YOLOv8 ê¸°ë°˜ ì•™ìƒë¸” ê°ì²´ íƒì§€ë¥¼ ë¹„ë””ì˜¤ì— ì ìš©í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.

import subprocess
import sys
import os

# í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ìë™ ì„¤ì¹˜í•˜ëŠ” í•¨ìˆ˜
def install_packages():
    packages = ['ultralytics', 'opencv-python', 'numpy', 'matplotlib']
    for package in packages:
        try:
            if package == 'opencv-python':
                import cv2
            elif package == 'ultralytics':
                from ultralytics import YOLO
            else:
                __import__(package)
            print(f"âœ… {package} ì„¤ì¹˜ë¨")
        except ImportError:
            print(f"ğŸ“¦ {package} ì„¤ì¹˜ ì¤‘...")
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '--quiet'])

install_packages()  # ìœ„ í•¨ìˆ˜ í˜¸ì¶œí•˜ì—¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import cv2
import numpy as np
from collections import defaultdict
import zipfile
import warnings
warnings.filterwarnings('ignore')

from ultralytics import YOLO
from google.colab import files
import matplotlib.pyplot as plt
from IPython.display import display, HTML

# YOLO ëª¨ë¸ì„ í™œìš©í•œ ë¹„ë””ì˜¤ ì•™ìƒë¸” íƒì§€ í´ë˜ìŠ¤ ì •ì˜
class VideoEnsembleDetector:
    def __init__(self):
        """YOLOv8 ëª¨ë¸ê³¼ ì•™ìƒë¸” ì„¤ì • ì´ˆê¸°í™”"""
        print("ğŸ¤– ì•™ìƒë¸” ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = YOLO('yolov8n.pt')  # ê°€ë³ê³  ë¹ ë¥¸ YOLOv8n ì‚¬ìš©
        print("âœ… YOLOv8n ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

        # ì—¬ëŸ¬ confidence thresholdë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì•™ìƒë¸” êµ¬ì„±
        self.ensemble_configs = [
            {'conf': 0.15, 'weight': 0.2},
            {'conf': 0.25, 'weight': 0.3},
            {'conf': 0.35, 'weight': 0.3},
            {'conf': 0.45, 'weight': 0.2}
        ]

        # ë„ë¡œ í™˜ê²½ì—ì„œ ì£¼ìš” í´ë˜ìŠ¤ë§Œ ì‚¬ìš©
        self.target_classes = {
            'person': 0, 'bicycle': 1, 'car': 2, 'motorcycle': 3,
            'bus': 5, 'truck': 7, 'traffic light': 9, 'stop sign': 11
        }

        # ê° í´ë˜ìŠ¤ì— ìƒ‰ìƒ ë§¤í•‘
        self.colors = {
            'person': (0, 255, 0), 'bicycle': (255, 0, 0), 'car': (0, 0, 255),
            'motorcycle': (255, 255, 0), 'bus': (128, 0, 128),
            'truck': (255, 165, 0), 'traffic light': (0, 255, 255),
            'stop sign': (255, 0, 255)
        }
        self.iou_threshold = 0.5  # NMS ì ìš© ì‹œ IOU ê¸°ì¤€

    def upload_video(self):
        """Colab í™˜ê²½ì—ì„œ ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ"""
        uploaded = files.upload()
        if not uploaded:
            return None, None
        filename = list(uploaded.keys())[0]
        return filename, filename.split('.')[0]

    def ensemble_predict(self, frame):
        """ë‹¤ì¤‘ thresholdë¡œ ì˜ˆì¸¡ í›„ ê²°ê³¼ ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”"""
        all_detections = []
        for config in self.ensemble_configs:
            results = self.model(frame, conf=config['conf'], verbose=False)
            weight = config['weight']
            for result in results:
                for box in result.boxes:
                    cls_id = int(box.cls[0])
                    conf = float(box.conf[0]) * weight
                    bbox = box.xyxy[0].cpu().numpy()
                    all_detections.append({
                        'bbox': bbox, 'conf': conf,
                        'cls_id': cls_id, 'threshold': config['conf']
                    })
        return all_detections

    def weighted_nms(self, detections):
        """ê°€ì¤‘ì¹˜ ê¸°ë°˜ NMS ì ìš©í•˜ì—¬ ìµœì¢… ë°•ìŠ¤ í•„í„°ë§"""
        if not detections:
            return []
        class_detections = defaultdict(list)
        for det in detections:
            class_detections[det['cls_id']].append(det)

        final_detections = []
        for cls_id, cls_dets in class_detections.items():
            cls_dets.sort(key=lambda x: x['conf'], reverse=True)
            kept = []
            for det in cls_dets:
                if all(self.calculate_iou(det['bbox'], k['bbox']) <= self.iou_threshold for k in kept):
                    kept.append(det)
                if len(kept) >= 15:
                    break
            final_detections.extend(kept)
        return final_detections

    def calculate_iou(self, bbox1, bbox2):
        """IoU ê³„ì‚° í•¨ìˆ˜"""
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        xi1, yi1 = max(x1_1, x1_2), max(y1_1, y1_2)
        xi2, yi2 = min(x2_1, x2_2), min(y2_1, y2_2)
        if xi2 <= xi1 or yi2 <= yi1:
            return 0.0
        inter = (xi2 - xi1) * (yi2 - yi1)
        union = ((x2_1 - x1_1) * (y2_1 - y1_1)) + ((x2_2 - x1_2) * (y2_2 - y1_2)) - inter
        return inter / union if union > 0 else 0.0

    def draw_detections(self, frame, detections):
        """íƒì§€ëœ ê°ì²´ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°"""
        class_names = self.model.names
        for det in detections:
            class_name = class_names.get(det['cls_id'], 'unknown')
            if class_name not in self.target_classes:
                continue
            x1, y1, x2, y2 = map(int, det['bbox'])
            color = self.colors.get(class_name, (255, 255, 255))
            label = f"{class_name}: {det['conf']:.2f}"
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
            cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w, y1), color, -1)
            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        return frame

    def process_video(self, video_path, max_frames=900):
        """ë¹„ë””ì˜¤ íŒŒì¼ì„ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ ë¹„ë””ì˜¤ ìƒì„±"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return None, {}

        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        process_frames = min(total_frames, max_frames)

        output_path = "ensemble_detected_video.mp4"
        out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

        detection_stats = defaultdict(int)
        frame_count = 0
        while frame_count < process_frames:
            ret, frame = cap.read()
            if not ret:
                break
            frame_count += 1
            detections = self.ensemble_predict(frame)
            filtered = self.weighted_nms(detections)
            class_names = self.model.names
            for det in filtered:
                class_name = class_names.get(det['cls_id'], 'unknown')
                if class_name in self.target_classes:
                    detection_stats[class_name] += 1
            result_frame = self.draw_detections(frame.copy(), filtered)
            info = f"Frame: {frame_count}/{process_frames}"
            cv2.putText(result_frame, info, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
            det_info = f"Current detections: {len(filtered)}"
            cv2.putText(result_frame, det_info, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)
            out.write(result_frame)

        cap.release()
        out.release()
        return output_path, detection_stats

    def create_final_package(self, video_path, stats, title):
        """ë¹„ë””ì˜¤ì™€ ë¦¬í¬íŠ¸ë¥¼ ZIPìœ¼ë¡œ ì••ì¶•"""
        stats_file = "ensemble_detection_report.txt"
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write(f"ë¹„ë””ì˜¤: {title}\n")
            f.write("ì‚¬ìš© ëª¨ë¸: YOLOv8n\n")
            f.write("ì•™ìƒë¸” ë°©ì‹: ë‹¤ì¤‘ Confidence Threshold\n")
            f.write("íƒì§€ í†µê³„:\n")
            total = sum(stats.values())
            for cls, cnt in stats.items():
                pct = (cnt / total * 100) if total > 0 else 0
                f.write(f"- {cls}: {cnt}íšŒ ({pct:.1f}%)\n")
        zip_name = f"{title}_ensemble_detection.zip"
        with zipfile.ZipFile(zip_name, 'w') as zipf:
            zipf.write(video_path, "ensemble_detected_video.mp4")
            zipf.write(stats_file, "detection_report.txt")
        os.remove(stats_file)
        return zip_name

    def run_detection(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        video_path, title = self.upload_video()
        if not video_path:
            return
        output_video, stats = self.process_video(video_path)
        if not output_video:
            return
        zip_file = self.create_final_package(output_video, stats, title)
        files.download(zip_file)

# ì‹¤í–‰
if __name__ == '__main__':
    detector = VideoEnsembleDetector()
    detector.run_detection()


# â–¶ï¸ ì‹¤í–‰
detector = VideoEnsembleDetector()
detector.run_detection()
```
## ê²°ê³¼
<img width="1052" height="590" alt="image" src="https://github.com/user-attachments/assets/3cff8944-d8ae-4a3f-8d7d-8bc8ca48bf54" />
<img width="1066" height="494" alt="image" src="https://github.com/user-attachments/assets/aa1c49db-1ec2-4e0e-8c41-c58ad065bdc2" />


### ê²°ê³¼ í•´ì„

- detect_stats.jsonì€ í”„ë ˆì„ ë‹¨ìœ„ì˜ í´ë˜ìŠ¤ í†µê³„ë¥¼ í¬í•¨í•˜ë¯€ë¡œ

- íŠ¹ì • í´ë˜ìŠ¤ê°€ ì–¸ì œ ìì£¼ ë‚˜íƒ€ë‚¬ëŠ”ì§€ ë¶„ì„ ê°€ëŠ¥

- ì˜ìƒ ì¶œë ¥ì€ ì‹œê°ì ìœ¼ë¡œ ì‹ ë¢°ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒ‰ìƒ ì°¨ë“±ì„ ë‘ì–´ ê°•ì¡°

