{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmRQV0nmbUoc67AncgYi0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiyeonjin/0624_new/blob/main/0731_Ensamble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Qg2NO3H12dh"
      },
      "outputs": [],
      "source": [
        "# 1. ê¸°ë³¸ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸\n",
        "!apt update -qq\n",
        "\n",
        "# 2. FFmpeg ì„¤ì¹˜ (ë¹„ë””ì˜¤ ì²˜ë¦¬ìš©)\n",
        "!apt install -y ffmpeg\n",
        "\n",
        "# 3. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "!pip install ultralytics  # YOLOv8\n",
        "!pip install yt-dlp       # YouTube ë‹¤ìš´ë¡œë”\n",
        "!pip install opencv-python\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# 4. ì¶”ê°€ ì˜ì¡´ì„± íŒ¨í‚¤ì§€\n",
        "!pip install numpy matplotlib pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¹„ë””ì˜¤ íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ ë°©ì‹ ì•™ìƒë¸” ê°ì²´ íƒì§€\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\"\"\"\n",
        "    packages = ['ultralytics', 'opencv-python', 'numpy', 'matplotlib']\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            if package == 'opencv-python':\n",
        "                import cv2\n",
        "            elif package == 'ultralytics':\n",
        "                from ultralytics import YOLO\n",
        "            else:\n",
        "                __import__(package)\n",
        "            print(f\"âœ… {package} ì„¤ì¹˜ë¨\")\n",
        "        except ImportError:\n",
        "            print(f\"ğŸ“¦ {package} ì„¤ì¹˜ ì¤‘...\")\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '--quiet'])\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "install_packages()\n",
        "\n",
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import zipfile\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ!\")\n",
        "\n",
        "class VideoEnsembleDetector:\n",
        "    def __init__(self):\n",
        "        \"\"\"ë¹„ë””ì˜¤ ì•™ìƒë¸” ê°ì²´ íƒì§€ê¸° ì´ˆê¸°í™”\"\"\"\n",
        "        print(\"ğŸ¤– ì•™ìƒë¸” ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
        "\n",
        "        try:\n",
        "            # ê°€ë²¼ìš´ ëª¨ë¸ í•˜ë‚˜ë¡œ ë‹¤ì¤‘ ì˜ˆì¸¡ ì•™ìƒë¸”\n",
        "            self.model = YOLO('yolov8n.pt')\n",
        "            print(\"âœ… YOLOv8n ëª¨ë¸ ë¡œë”© ì™„ë£Œ\")\n",
        "\n",
        "            # ì•™ìƒë¸” ì„¤ì •: ë‹¤ì¤‘ confidence threshold ì‚¬ìš©\n",
        "            self.ensemble_configs = [\n",
        "                {'conf': 0.15, 'weight': 0.2},\n",
        "                {'conf': 0.25, 'weight': 0.3},\n",
        "                {'conf': 0.35, 'weight': 0.3},\n",
        "                {'conf': 0.45, 'weight': 0.2}\n",
        "            ]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
        "            return\n",
        "\n",
        "        # ë„ë¡œ ì£¼í–‰ ê´€ë ¨ í´ë˜ìŠ¤\n",
        "        self.target_classes = {\n",
        "            'person': 0, 'bicycle': 1, 'car': 2, 'motorcycle': 3,\n",
        "            'bus': 5, 'truck': 7, 'traffic light': 9, 'stop sign': 11\n",
        "        }\n",
        "\n",
        "        # ìƒ‰ìƒ ë§¤í•‘\n",
        "        self.colors = {\n",
        "            'person': (0, 255, 0),      # ì´ˆë¡\n",
        "            'bicycle': (255, 0, 0),     # íŒŒë‘\n",
        "            'car': (0, 0, 255),         # ë¹¨ê°•\n",
        "            'motorcycle': (255, 255, 0), # ì‹œì•ˆ\n",
        "            'bus': (128, 0, 128),       # ë³´ë¼\n",
        "            'truck': (255, 165, 0),     # ì£¼í™©\n",
        "            'traffic light': (0, 255, 255), # ë…¸ë‘\n",
        "            'stop sign': (255, 0, 255)  # ë§ˆì  íƒ€\n",
        "        }\n",
        "\n",
        "        self.iou_threshold = 0.5\n",
        "        print(\"ğŸ¯ ì•™ìƒë¸” íƒì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
        "\n",
        "    def upload_video(self):\n",
        "        \"\"\"Colabì—ì„œ ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ\"\"\"\n",
        "        print(\"ğŸ“ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”...\")\n",
        "        print(\"ğŸ’¡ ê¶Œì¥: MP4, AVI, MOV ë“±ì˜ ì¼ë°˜ì ì¸ ë¹„ë””ì˜¤ í˜•ì‹\")\n",
        "        print(\"ğŸ’¡ ê¶Œì¥: íŒŒì¼ í¬ê¸° 100MB ì´í•˜, ê¸¸ì´ 5ë¶„ ì´í•˜\")\n",
        "\n",
        "        try:\n",
        "            uploaded = files.upload()\n",
        "\n",
        "            if not uploaded:\n",
        "                print(\"âŒ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "                return None, None\n",
        "\n",
        "            # ì—…ë¡œë“œëœ íŒŒì¼ í™•ì¸\n",
        "            filename = list(uploaded.keys())[0]\n",
        "            filesize_mb = len(uploaded[filename]) / (1024 * 1024)\n",
        "\n",
        "            print(f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {filename}\")\n",
        "            print(f\"ğŸ“ íŒŒì¼ í¬ê¸°: {filesize_mb:.1f}MB\")\n",
        "\n",
        "            # ë¹„ë””ì˜¤ íŒŒì¼ì¸ì§€ í™•ì¸\n",
        "            video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv']\n",
        "            if not any(filename.lower().endswith(ext) for ext in video_extensions):\n",
        "                print(\"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤. MP4, AVI, MOV ë“±ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.\")\n",
        "                return None, None\n",
        "\n",
        "            return filename, filename.split('.')[0]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
        "            return None, None\n",
        "\n",
        "    def ensemble_predict(self, frame):\n",
        "        \"\"\"ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰\"\"\"\n",
        "        all_detections = []\n",
        "\n",
        "        # ê° confidence thresholdë¡œ ì˜ˆì¸¡\n",
        "        for config in self.ensemble_configs:\n",
        "            try:\n",
        "                results = self.model(frame, conf=config['conf'], verbose=False)\n",
        "                weight = config['weight']\n",
        "\n",
        "                for result in results:\n",
        "                    if result.boxes is not None:\n",
        "                        for box in result.boxes:\n",
        "                            cls_id = int(box.cls[0])\n",
        "                            conf = float(box.conf[0]) * weight  # ê°€ì¤‘ì¹˜ ì ìš©\n",
        "                            bbox = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "                            all_detections.append({\n",
        "                                'bbox': bbox,\n",
        "                                'conf': conf,\n",
        "                                'cls_id': cls_id,\n",
        "                                'threshold': config['conf']\n",
        "                            })\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        return all_detections\n",
        "\n",
        "    def weighted_nms(self, detections):\n",
        "        \"\"\"ê°€ì¤‘ì¹˜ ê¸°ë°˜ NMS\"\"\"\n",
        "        if not detections:\n",
        "            return []\n",
        "\n",
        "        # í´ë˜ìŠ¤ë³„ë¡œ ë¶„ë¦¬\n",
        "        class_detections = defaultdict(list)\n",
        "        for det in detections:\n",
        "            class_detections[det['cls_id']].append(det)\n",
        "\n",
        "        final_detections = []\n",
        "\n",
        "        for cls_id, cls_dets in class_detections.items():\n",
        "            # confidence ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
        "            cls_dets.sort(key=lambda x: x['conf'], reverse=True)\n",
        "\n",
        "            kept = []\n",
        "            for det in cls_dets:\n",
        "                bbox1 = det['bbox']\n",
        "                should_keep = True\n",
        "\n",
        "                # ê¸°ì¡´ kept ë°•ìŠ¤ë“¤ê³¼ IoU ë¹„êµ\n",
        "                for kept_det in kept:\n",
        "                    bbox2 = kept_det['bbox']\n",
        "                    if self.calculate_iou(bbox1, bbox2) > self.iou_threshold:\n",
        "                        should_keep = False\n",
        "                        break\n",
        "\n",
        "                if should_keep:\n",
        "                    kept.append(det)\n",
        "                    if len(kept) >= 15:  # í´ë˜ìŠ¤ë‹¹ ìµœëŒ€ 15ê°œ\n",
        "                        break\n",
        "\n",
        "            final_detections.extend(kept)\n",
        "\n",
        "        return final_detections\n",
        "\n",
        "    def calculate_iou(self, bbox1, bbox2):\n",
        "        \"\"\"IoU ê³„ì‚°\"\"\"\n",
        "        try:\n",
        "            x1_1, y1_1, x2_1, y2_1 = bbox1\n",
        "            x1_2, y1_2, x2_2, y2_2 = bbox2\n",
        "\n",
        "            # êµì§‘í•©\n",
        "            xi1, yi1 = max(x1_1, x1_2), max(y1_1, y1_2)\n",
        "            xi2, yi2 = min(x2_1, x2_2), min(y2_1, y2_2)\n",
        "\n",
        "            if xi2 <= xi1 or yi2 <= yi1:\n",
        "                return 0.0\n",
        "\n",
        "            inter = (xi2 - xi1) * (yi2 - yi1)\n",
        "            union = (x2_1 - x1_1) * (y2_1 - y1_1) + (x2_2 - x1_2) * (y2_2 - y1_2) - inter\n",
        "\n",
        "            return inter / union if union > 0 else 0.0\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def draw_detections(self, frame, detections):\n",
        "        \"\"\"íƒì§€ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
        "        class_names = self.model.names\n",
        "\n",
        "        for det in detections:\n",
        "            bbox = det['bbox']\n",
        "            conf = det['conf']\n",
        "            cls_id = det['cls_id']\n",
        "\n",
        "            class_name = class_names.get(cls_id, 'unknown')\n",
        "            if class_name not in self.target_classes:\n",
        "                continue\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "            color = self.colors.get(class_name, (255, 255, 255))\n",
        "\n",
        "            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "            # ë¼ë²¨ ê·¸ë¦¬ê¸°\n",
        "            label = f\"{class_name}: {conf:.2f}\"\n",
        "            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
        "\n",
        "            # ë¼ë²¨ ë°°ê²½\n",
        "            cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w, y1), color, -1)\n",
        "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
        "\n",
        "        return frame\n",
        "\n",
        "    def process_video(self, video_path, max_frames=900):\n",
        "        \"\"\"ë¹„ë””ì˜¤ ì²˜ë¦¬ (ìµœëŒ€ 900í”„ë ˆì„ = 30ì´ˆ@30fps)\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(\"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return None, {}\n",
        "\n",
        "        # ë¹„ë””ì˜¤ ì •ë³´\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        # ì²˜ë¦¬í•  í”„ë ˆì„ ìˆ˜ ê²°ì •\n",
        "        process_frames = min(total_frames, max_frames)\n",
        "\n",
        "        print(f\"ğŸ¬ ë¹„ë””ì˜¤ ì •ë³´:\")\n",
        "        print(f\"   í•´ìƒë„: {width}x{height}\")\n",
        "        print(f\"   FPS: {fps}\")\n",
        "        print(f\"   ì´ í”„ë ˆì„: {total_frames}\")\n",
        "        print(f\"   ì²˜ë¦¬í•  í”„ë ˆì„: {process_frames}\")\n",
        "\n",
        "        # ì¶œë ¥ ë¹„ë””ì˜¤ ì„¤ì •\n",
        "        output_path = \"ensemble_detected_video.mp4\"\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        frame_count = 0\n",
        "        detection_stats = defaultdict(int)\n",
        "\n",
        "        print(f\"\\nğŸ” ì•™ìƒë¸” ê°ì²´ íƒì§€ ì‹œì‘ (4ê°œ threshold ì‚¬ìš©)...\")\n",
        "\n",
        "        while frame_count < process_frames:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "            # ì§„í–‰ë¥  í‘œì‹œ\n",
        "            if frame_count % max(1, process_frames // 20) == 0:\n",
        "                progress = (frame_count / process_frames) * 100\n",
        "                print(f\"â³ {progress:.0f}% ì™„ë£Œ ({frame_count}/{process_frames})\")\n",
        "\n",
        "            # ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "            detections = self.ensemble_predict(frame)\n",
        "            filtered_detections = self.weighted_nms(detections)\n",
        "\n",
        "            # í†µê³„ ì—…ë°ì´íŠ¸\n",
        "            class_names = self.model.names\n",
        "            for det in filtered_detections:\n",
        "                class_name = class_names.get(det['cls_id'], 'unknown')\n",
        "                if class_name in self.target_classes:\n",
        "                    detection_stats[class_name] += 1\n",
        "\n",
        "            # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°\n",
        "            result_frame = self.draw_detections(frame.copy(), filtered_detections)\n",
        "\n",
        "            # í”„ë ˆì„ ì •ë³´ ì¶”ê°€\n",
        "            info = f\"Frame: {frame_count}/{process_frames} | Ensemble: 4 thresholds\"\n",
        "            cv2.putText(result_frame, info, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "            # í˜„ì¬ í”„ë ˆì„ íƒì§€ ìˆ˜ í‘œì‹œ\n",
        "            current_detections = len(filtered_detections)\n",
        "            det_info = f\"Current detections: {current_detections}\"\n",
        "            cv2.putText(result_frame, det_info, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
        "\n",
        "            out.write(result_frame)\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        print(f\"âœ… ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "        print(f\"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_path}\")\n",
        "\n",
        "        return output_path, detection_stats\n",
        "\n",
        "    def create_final_package(self, video_path, stats, title):\n",
        "        \"\"\"ìµœì¢… ê²°ê³¼ íŒ¨í‚¤ì§€ ìƒì„±\"\"\"\n",
        "        # í†µê³„ íŒŒì¼ ìƒì„±\n",
        "        stats_file = \"ensemble_detection_report.txt\"\n",
        "\n",
        "        with open(stats_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"=\" * 50 + \"\\n\")\n",
        "            f.write(\"ì•™ìƒë¸” ê°ì²´ íƒì§€ ê²°ê³¼ ë¦¬í¬íŠ¸\\n\")\n",
        "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "            f.write(f\"ë¹„ë””ì˜¤ íŒŒì¼: {title}\\n\")\n",
        "            f.write(f\"ì‚¬ìš© ëª¨ë¸: YOLOv8n\\n\")\n",
        "            f.write(f\"ì•™ìƒë¸” ë°©ì‹: ë‹¤ì¤‘ Confidence Threshold\\n\")\n",
        "            f.write(f\"ì‚¬ìš©ëœ Threshold: {[cfg['conf'] for cfg in self.ensemble_configs]}\\n\")\n",
        "            f.write(f\"ê°€ì¤‘ì¹˜: {[cfg['weight'] for cfg in self.ensemble_configs]}\\n\\n\")\n",
        "\n",
        "            f.write(\"íƒì§€ ê²°ê³¼ í†µê³„:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "            total = sum(stats.values())\n",
        "            for class_name, count in sorted(stats.items(), key=lambda x: x[1], reverse=True):\n",
        "                percentage = (count / total * 100) if total > 0 else 0\n",
        "                f.write(f\"{class_name:15} : {count:4d}íšŒ ({percentage:5.1f}%)\\n\")\n",
        "\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            f.write(f\"ì´ íƒì§€ íšŸìˆ˜: {total}íšŒ\\n\")\n",
        "\n",
        "            # í´ë˜ìŠ¤ë³„ ì„¤ëª…\n",
        "            f.write(\"\\ní´ë˜ìŠ¤ ì„¤ëª…:\\n\")\n",
        "            class_desc = {\n",
        "                'person': 'ë³´í–‰ì/ì‚¬ëŒ',\n",
        "                'bicycle': 'ìì „ê±°',\n",
        "                'car': 'ìŠ¹ìš©ì°¨',\n",
        "                'motorcycle': 'ì˜¤í† ë°”ì´',\n",
        "                'bus': 'ë²„ìŠ¤',\n",
        "                'truck': 'íŠ¸ëŸ­',\n",
        "                'traffic light': 'ì‹ í˜¸ë“±',\n",
        "                'stop sign': 'ì •ì§€ í‘œì§€íŒ'\n",
        "            }\n",
        "\n",
        "            for cls, desc in class_desc.items():\n",
        "                if cls in stats:\n",
        "                    f.write(f\"- {cls}: {desc}\\n\")\n",
        "\n",
        "        # ZIP íŒŒì¼ ìƒì„±\n",
        "        zip_filename = f\"{title}_ensemble_detection.zip\"\n",
        "\n",
        "        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            # ë¹„ë””ì˜¤ íŒŒì¼ ì¶”ê°€\n",
        "            if os.path.exists(video_path):\n",
        "                zipf.write(video_path, \"ensemble_detected_video.mp4\")\n",
        "\n",
        "            # í†µê³„ íŒŒì¼ ì¶”ê°€\n",
        "            zipf.write(stats_file, \"detection_report.txt\")\n",
        "\n",
        "        # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n",
        "        if os.path.exists(stats_file):\n",
        "            os.remove(stats_file)\n",
        "\n",
        "        return zip_filename\n",
        "\n",
        "    def run_detection(self):\n",
        "        \"\"\"ì „ì²´ íƒì§€ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰\"\"\"\n",
        "        print(\"ğŸ¯ ë¹„ë””ì˜¤ íŒŒì¼ ì•™ìƒë¸” ê°ì²´ íƒì§€ê¸°\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"ì—¬ëŸ¬ confidence thresholdë¥¼ ì‚¬ìš©í•œ ì•™ìƒë¸” ë°©ì‹ìœ¼ë¡œ\")\n",
        "        print(\"ë” ì •í™•í•œ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        try:\n",
        "            # 1. ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ\n",
        "            print(\"\\n1ï¸âƒ£ ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ\")\n",
        "            video_path, title = self.upload_video()\n",
        "\n",
        "            if not video_path:\n",
        "                print(\"âŒ ë¹„ë””ì˜¤ ì—…ë¡œë“œ ì‹¤íŒ¨\")\n",
        "                return\n",
        "\n",
        "            # 2. ì•™ìƒë¸” ê°ì²´ íƒì§€ ìˆ˜í–‰\n",
        "            print(f\"\\n2ï¸âƒ£ ì•™ìƒë¸” ê°ì²´ íƒì§€ ìˆ˜í–‰\")\n",
        "            output_video, stats = self.process_video(video_path)\n",
        "\n",
        "            if not output_video:\n",
        "                print(\"âŒ ê°ì²´ íƒì§€ ì‹¤íŒ¨\")\n",
        "                return\n",
        "\n",
        "            # 3. ê²°ê³¼ ë¶„ì„ ì¶œë ¥\n",
        "            print(f\"\\n3ï¸âƒ£ íƒì§€ ê²°ê³¼ ë¶„ì„\")\n",
        "            total_detections = sum(stats.values())\n",
        "            print(f\"ğŸ“Š ì´ íƒì§€ íšŸìˆ˜: {total_detections}íšŒ\")\n",
        "\n",
        "            if stats:\n",
        "                print(\"ğŸ“ˆ í´ë˜ìŠ¤ë³„ íƒì§€ ê²°ê³¼:\")\n",
        "                for class_name, count in sorted(stats.items(), key=lambda x: x[1], reverse=True):\n",
        "                    percentage = (count / total_detections * 100) if total_detections > 0 else 0\n",
        "                    emoji = {'person': 'ğŸ‘¤', 'car': 'ğŸš—', 'bicycle': 'ğŸš²', 'motorcycle': 'ğŸï¸',\n",
        "                            'bus': 'ğŸšŒ', 'truck': 'ğŸš›', 'traffic light': 'ğŸš¦', 'stop sign': 'ğŸ›‘'}.get(class_name, 'ğŸ¯')\n",
        "                    print(f\"   {emoji} {class_name}: {count}íšŒ ({percentage:.1f}%)\")\n",
        "\n",
        "            # 4. ê²°ê³¼ íŒ¨í‚¤ì§€ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ\n",
        "            print(f\"\\n4ï¸âƒ£ ê²°ê³¼ íŒ¨í‚¤ì§€ ìƒì„±\")\n",
        "            zip_file = self.create_final_package(output_video, stats, title)\n",
        "\n",
        "            print(f\"ğŸ“¦ ê²°ê³¼ íŒ¨í‚¤ì§€: {zip_file}\")\n",
        "            print(\"ğŸ’¾ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
        "            files.download(zip_file)\n",
        "\n",
        "            print(f\"\\nğŸ‰ ì•™ìƒë¸” ê°ì²´ íƒì§€ ì™„ë£Œ!\")\n",
        "            print(\"ğŸ“ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ë‚´ìš©:\")\n",
        "            print(\"   - ensemble_detected_video.mp4 (íƒì§€ ê²°ê³¼ ì˜ìƒ)\")\n",
        "            print(\"   - detection_report.txt (ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            print(\"ğŸ’¡ íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•˜ê±°ë‚˜ Colabì„ ì¬ì‹œì‘í•´ë³´ì„¸ìš”.\")\n",
        "\n",
        "# ì‹¤í–‰\n",
        "detector = VideoEnsembleDetector()\n",
        "detector.run_detection()"
      ],
      "metadata": {
        "id": "6h4GJFqi1_iW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}