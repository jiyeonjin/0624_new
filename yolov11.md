# YOLOv11 내용 정리

YOLOv11은 **You Only Look Once (YOLO)** 시리즈의 최신 객체 탐지 알고리즘으로, 속도와 정확도 양쪽을 모두 잡은 혁신적인 모델입니다.  
YOLOv8 이후 등장한 YOLOv11은 **성능 향상**, **유연한 백본 구조**, **확장성 높은 디자인** 등에서 크게 개선되었습니다.


---

## 1. 📌 YOLO란?

YOLO(You Only Look Once)는 딥러닝 기반 객체 탐지 알고리즘입니다.  
한 번의 신경망 연산으로 이미지 내 모든 객체의 **위치**와 **클래스**를 동시에 예측합니다.

- 입력: 이미지
- 출력: 객체의 위치(바운딩 박스) + 클래스(Label)

---

## 2. 📌 YOLOv11 개요

YOLOv11은 2024년 중반에 발표된 YOLO 시리즈의 최신 버전입니다.  
기존 YOLOv8의 구조를 크게 개선하며, 다음과 같은 특징을 가집니다:

- **더 가볍고 빠른 백본**
- **Transformer와 Conv의 하이브리드 구조**
- **동적 해상도 처리 (Dynamic Input Resizing)**
- **더 강력한 Anchor-free 방식**

---

## 3. 📊 YOLOv8 vs YOLOv11 

| 항목                     | YOLOv8                            | YOLOv11                              |
|--------------------------|------------------------------------|---------------------------------------|
| 출시 연도                | 2023년                            | 2024년                                |
| 백본 구조               | C2f 기반                           | C2f + Lightweight Hybrid Transformer |
| Anchor 방식             | Anchor-free                       | Anchor-free (개선된 디코더)          |
| 아키텍처 확장성         | 보통                               | 뛰어남 (모듈형 설계)                  |
| 성능 (mAP50 기준)       | 약 53~56%                          | 약 56~59% (더 높음)                   |
| 파라미터 수             | 더 많음                           | 최적화로 파라미터 수 감소             |
| 학습 유연성              | Good                               | Excellent                             |
| 영상 추론 속도 (RTSP 등)| 빠름                              | 더 빠름                               |

---

## 4. 🧾 yolov11에서 자주 쓰이는 용어 정리

| 용어              | 설명 |
|------------------|------|
| **Backbone**     | 특징 추출기 역할. 이미지에서 의미 있는 정보를 뽑아냄. |
| **Neck**         | 특징을 통합하는 부분. PANet, FPN 등이 해당됨. |
| **Head**         | 최종 예측을 수행하는 부분. 클래스, 바운딩 박스 출력. |
| **Anchor-free**  | 기존 anchor box 없이 객체 위치를 직접 예측하는 방식. |
| **NMS (Non-Max Suppression)** | 중복되는 바운딩 박스를 제거하는 알고리즘. |
| **mAP (mean Average Precision)** | 모델 정확도를 수치로 나타내는 지표. |
| **IoU (Intersection over Union)** | 예측 박스와 실제 박스의 겹침 비율. |
| **FP16 / INT8**  | 연산 속도를 높이기 위한 정밀도 감소 기법. |

---

## 5. ⚙️ YOLOv11 핵심 구조

YOLOv11은 기존의 CNN 기반에 **Transformer 요소**를 추가한 하이브리드 구조입니다.

입력 이미지
↓
[Backbone] C2f + Transformer block
↓
[Neck] PAN 구조 개선 + Dynamic Scale
↓
[Head] Anchor-free + Bounding Box + Class 예측
↓
[후처리] NMS, 결과 필터링


### YOLOv11의 주요 모듈
- **Backbone**: C2f + Lightweight Transformer → 더 강한 표현력
- **Neck**: PANet 향상 구조 + Dynamic Features
- **Head**: 더 정확한 클래스 및 위치 예측 (anchor-free)
- **Loss**: 개선된 CIoU, BCE Loss 등 사용

---

## 6. yolov11의 장점과 단점

### ✅ 장점
- 기존 YOLO보다 **더 빠르고 정확**함
- Transformer와 Conv의 **장점만 조합**
- **실시간 추론 성능 탁월**
- **경량화 모델 제공** → 모바일 디바이스에서도 사용 가능

### ❌ 단점
- 학습 코드 구조가 복잡해졌음
- 완전히 새로운 구조여서 기존 커스텀 코드 재활용이 어려움
- Transformer 기반이라 RAM 사용량이 다소 높을 수 있음

---

## 7. 💻 사용 예시 (Python + Ultralytics)

1.
```python
# YOLOv11 설치 (예: ultralytics 팀이 제공할 경우)
!pip install yolov11

from yolov11 import YOLO

model = YOLO("yolov11.pt")  # 사전 학습된 모델 로드
results = model("image.jpg")  # 이미지 추론
results.show()  # 결과 시각화
```

2. yolov11n.pt 파일 다운받는 깃허브 링크 -> https://github.com/ultralytics/ultralytics
3. Colab에서 확인하기 -> https://colab.research.google.com/drive/1P3frk0hH18uVFdbn2x9uLC0c9DDmU0ub



