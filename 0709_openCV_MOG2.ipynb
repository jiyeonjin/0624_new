{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBw1q4FlhmSdG8nIFK5srI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiyeonjin/0624_new/blob/main/0709_openCV_MOG2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIUOBzcveuR5"
      },
      "outputs": [],
      "source": [
        "# 1. 기본 MOG2 차량 감지 코드\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 동영상 파일 열기 (코랩에서는 업로드한 파일 경로 사용)\n",
        "cap = cv2.VideoCapture('/content/sample_data/around 5.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "\n",
        "# MOG2 배경 차분기 생성\n",
        "backSub = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 배경 차분 적용\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "    # 매 30프레임마다 결과 출력 (너무 많은 출력 방지)\n",
        "    if frame_count % 20 == 0:   # 20초마다 1프레임\n",
        "        # 결과를 나란히 표시\n",
        "        combined = np.hstack((frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 정도만 처리 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "\n",
        "# 자원 해제\n",
        "cap.release() # cap,realease()매우 중요!\n",
        "print(\"처리 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 노이즈 제거 기능 추가"
      ],
      "metadata": {
        "id": "sA_17HBMmNtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 기본 MOG2 차량 감지 코드\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 동영상 파일 열기 (코랩에서는 업로드한 파일 경로 사용)\n",
        "cap = cv2.VideoCapture('/content/sample_data/around 5.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "\n",
        "# MOG2 배경 차분기 생성\n",
        "backSub = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 배경 차분 적용\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "    # 노이즈 제거 (모폴로지 연산)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)  # 작은 노이즈 제거\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)  # 구멍 메우기\n",
        "\n",
        "    # 매 30프레임마다 결과 출력 (너무 많은 출력 방지)\n",
        "    if frame_count % 10 == 0:   # 10초마다 1프레임\n",
        "        # 결과를 나란히 표시\n",
        "        combined = np.hstack((frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 정도만 처리 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "\n",
        "# 자원 해제\n",
        "cap.release() # cap,realease()매우 중요!\n",
        "print(\"처리 완료!\")"
      ],
      "metadata": {
        "id": "T_yYSTn2kqAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 바운딩 박스 추가"
      ],
      "metadata": {
        "id": "L0jBnjwToD0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 기본 MOG2 차량 감지 코드\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 동영상 파일 열기 (코랩에서는 업로드한 파일 경로 사용)\n",
        "cap = cv2.VideoCapture('/content/sample_data/around 5.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "\n",
        "# MOG2 배경 차분기 생성\n",
        "backSub = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 배경 차분 적용\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "    # 노이즈 제거 (모폴로지 연산)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)  # 작은 노이즈 제거\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)  # 구멍 메우기\n",
        "\n",
        "    # 윤곽선 검출 및 바운딩 박스\n",
        "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # 바운딩 박스를 그릴 프레임 복사\n",
        "    result_frame = frame.copy()\n",
        "\n",
        "    for contour in contours:\n",
        "        # 너무 작은 영역은 제외 (차량이 아닐 가능성 높음)\n",
        "        if cv2.contourArea(contour) > 3000:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            cv2.rectangle(result_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    # 매 30프레임마다 결과 출력 (너무 많은 출력 방지)\n",
        "    if frame_count % 10 == 0:   # 10초마다 1프레임\n",
        "        # 결과를 나란히 표시\n",
        "        combined = np.hstack((frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 정도만 처리 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "\n",
        "# 자원 해제\n",
        "cap.release() # cap,realease()매우 중요!\n",
        "print(\"처리 완료!\")"
      ],
      "metadata": {
        "id": "X7ahfn16nwJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 종횡비 필터 추가"
      ],
      "metadata": {
        "id": "2o4ZeApUpZhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 기본 MOG2 차량 감지 코드\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 동영상 파일 열기 (코랩에서는 업로드한 파일 경로 사용)\n",
        "cap = cv2.VideoCapture('/content/sample_data/around 5.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "\n",
        "# MOG2 배경 차분기 생성\n",
        "backSub = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 배경 차분 적용\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "    # 노이즈 제거 (모폴로지 연산)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)  # 작은 노이즈 제거\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)  # 구멍 메우기\n",
        "\n",
        "    # 윤곽선 검출 및 바운딩 박스\n",
        "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # 바운딩 박스를 그릴 프레임 복사\n",
        "    result_frame = frame.copy()\n",
        "\n",
        "    for contour in contours:\n",
        "        # 너무 작은 영역은 제외 (차량이 아닐 가능성 높음)\n",
        "        if cv2.contourArea(contour) > 3000:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            cv2.rectangle(result_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    # 매 30프레임마다 결과 출력 (너무 많은 출력 방지)\n",
        "    if frame_count % 10 == 0:   # 10초마다 1프레임\n",
        "        # 결과를 나란히 표시\n",
        "        combined = np.hstack((frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "        # 결과를 나란히 표시(바운딩 박스가 있는 프레임 + 마스크)\n",
        "        combined = np.hstack(((result_frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR))))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 정도만 처리 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "\n",
        "# 자원 해제\n",
        "cap.release() # cap,realease()매우 중요!\n",
        "print(\"처리 완료!\")"
      ],
      "metadata": {
        "id": "37Gapaq-pZJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# roi 영역 코드 포함"
      ],
      "metadata": {
        "id": "6y-nNvBLwceR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 동영상 파일 열기 (코랩에서는 업로드한 파일 경로 사용)\n",
        "cap = cv2.VideoCapture('/content/sample_data/around 5.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "# MOG2 배경 차분기 생성\n",
        "backSub = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "# ROI 설정 (도로 영역만 분석) - 좌표는 영상에 맞게 조정 필요\n",
        "def create_roi_mask(frame):\n",
        "    height, width = frame.shape[:2]\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    # 도로 영역을 다각형으로 설정 (예시 - 실제 영상에 맞게 조정)\n",
        "    roi_points = np.array([\n",
        "        [0, height//2],           # 왼쪽 중간\n",
        "        [width, height//2],       # 오른쪽 중간\n",
        "        [width, height],          # 오른쪽 아래\n",
        "        [0, height]               # 왼쪽 아래\n",
        "    ], np.int32)\n",
        "\n",
        "    cv2.fillPoly(mask, [roi_points], 255)\n",
        "    return mask\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 배경 차분 적용\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "    # ROI 마스크 생성 및 적용\n",
        "    roi_mask = create_roi_mask(frame)\n",
        "    fgMask = cv2.bitwise_and(fgMask, roi_mask)  # ROI 영역만 남김\n",
        "\n",
        "    # 노이즈 제거 (모폴로지 연산)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)  # 작은 노이즈 제거\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)  # 구멍 메우기\n",
        "\n",
        "    # 윤곽선 검출 및 바운딩 박스\n",
        "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # 바운딩 박스를 그릴 프레임 복사\n",
        "    result_frame = frame.copy()\n",
        "\n",
        "    for contour in contours:\n",
        "        # 너무 작은 영역은 제외 (차량이 아닐 가능성 높음)\n",
        "        if cv2.contourArea(contour) > 2000:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "            # 종횡비 필터 추가 (차량은 보통 가로가 세로보다 길거나 비슷함)\n",
        "            aspect_ratio = w / h\n",
        "            if 0.5 <= aspect_ratio <= 4.0:  # 너무 세로로 길거나 가로로 긴 것 제외\n",
        "                cv2.rectangle(result_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    # 매 30프레임마다 결과 출력 (너무 많은 출력 방지)\n",
        "    if frame_count % 10 == 0:\n",
        "        # 결과를 나란히 표시 (바운딩 박스가 있는 프레임 + 마스크)\n",
        "        combined = np.hstack((result_frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 정도만 처리 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "# 자원 해제\n",
        "cap.release()\n",
        "print(\"처리 완료!\")"
      ],
      "metadata": {
        "id": "xtK0Ly_EvYY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사다리꼴"
      ],
      "metadata": {
        "id": "alKPBEavy7fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 동영상 파일 열기\n",
        "cap = cv2.VideoCapture('/content/sample_data/around 5.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "# 차선 검출을 위한 ROI 설정 (도로 차선에 맞게 조정)\n",
        "def create_lane_roi(frame):\n",
        "    height, width = frame.shape[:2]\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    # 도로 차선에 맞는 사다리꼴 모양의 ROI (오른쪽으로 조금 이동)\n",
        "    roi_points = np.array([\n",
        "        [width//5, height],            # 왼쪽 아래 (20%)\n",
        "        [width*9//20, height*3//5],    # 왼쪽 위 (45%)\n",
        "        [width*13//20, height*3//5],   # 오른쪽 위 (65%)\n",
        "        [width*19//20, height]         # 오른쪽 아래 (95%)\n",
        "    ], np.int32)\n",
        "\n",
        "    cv2.fillPoly(mask, [roi_points], 255)\n",
        "    return mask\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 그레이스케일 변환\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 가우시안 블러로 노이즈 제거\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Canny 에지 검출\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "    # ROI 적용\n",
        "    roi_mask = create_lane_roi(frame)\n",
        "    masked_edges = cv2.bitwise_and(edges, roi_mask)\n",
        "\n",
        "    # 결과 프레임 복사\n",
        "    result_frame = frame.copy()\n",
        "\n",
        "    # ROI 영역을 시각화 (오른쪽으로 조금 이동한 사다리꼴 표시)\n",
        "    roi_points = np.array([\n",
        "        [frame.shape[1]//5, frame.shape[0]],            # 왼쪽 아래 (20%)\n",
        "        [frame.shape[1]*9//20, frame.shape[0]*3//5],    # 왼쪽 위 (45%)\n",
        "        [frame.shape[1]*13//20, frame.shape[0]*3//5],   # 오른쪽 위 (65%)\n",
        "        [frame.shape[1]*19//20, frame.shape[0]]         # 오른쪽 아래 (95%)\n",
        "    ], np.int32)\n",
        "\n",
        "    cv2.polylines(result_frame, [roi_points], True, (255, 0, 0), 2)  # 파란색 사다리꼴\n",
        "\n",
        "    # 매 30프레임마다 결과 출력\n",
        "    if frame_count % 30 == 0:\n",
        "        # 영어 라벨 추가\n",
        "        cv2.putText(result_frame, \"Original + ROI\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        edge_display = cv2.cvtColor(masked_edges, cv2.COLOR_GRAY2BGR)\n",
        "        cv2.putText(edge_display, \"Canny Edge Detection\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        # 결과를 나란히 표시 (원본+ROI + 에지검출)\n",
        "        combined = np.hstack((result_frame, edge_display))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 후 종료 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "# 자원 해제\n",
        "cap.release()\n",
        "print(\"차선 검출 처리 완료!\")"
      ],
      "metadata": {
        "id": "5DbuW8GEymaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 차선 따라가기"
      ],
      "metadata": {
        "id": "aHHz_slxBmXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 동영상 파일 열기\n",
        "cap = cv2.VideoCapture('/content/sample_data/around 5.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "# 차선 검출을 위한 ROI 설정\n",
        "def create_lane_roi(frame):\n",
        "    height, width = frame.shape[:2]\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    # 사다리꼴 모양의 ROI (차선이 있는 도로 영역)\n",
        "    roi_points = np.array([\n",
        "        [width//5, height],            # 왼쪽 아래 (20%)\n",
        "        [width*9//20, height*3//5],    # 왼쪽 위 (45%)\n",
        "        [width*13//20, height*3//5],   # 오른쪽 위 (65%)\n",
        "        [width*19//20, height]         # 오른쪽 아래 (95%)\n",
        "    ], np.int32)\n",
        "\n",
        "    cv2.fillPoly(mask, [roi_points], 255)\n",
        "    return mask\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 그레이스케일 변환\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 가우시안 블러로 노이즈 제거\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Canny 에지 검출\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "    # ROI 적용\n",
        "    roi_mask = create_lane_roi(frame)\n",
        "    masked_edges = cv2.bitwise_and(edges, roi_mask)\n",
        "\n",
        "    # Hough 변환으로 직선 검출\n",
        "    lines = cv2.HoughLinesP(masked_edges, 1, np.pi/180, threshold=50,\n",
        "                           minLineLength=50, maxLineGap=50)\n",
        "\n",
        "    # 결과 프레임들 복사\n",
        "    result_frame = frame.copy()\n",
        "    lane_frame = frame.copy()\n",
        "\n",
        "    # 차선 분류를 위한 리스트\n",
        "    left_lines = []\n",
        "    right_lines = []\n",
        "\n",
        "    # 검출된 차선을 좌/우로 분류\n",
        "    if lines is not None:\n",
        "        img_center = frame.shape[1] // 2  # 화면 중앙\n",
        "\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "\n",
        "            # 기울기 계산 (수직선 제외)\n",
        "            if x2 - x1 != 0:\n",
        "                slope = (y2 - y1) / (x2 - x1)\n",
        "\n",
        "                # 기울기와 위치로 좌/우 차선 분류\n",
        "                if slope < -0.3 and x1 < img_center:  # 왼쪽 차선 (음의 기울기)\n",
        "                    left_lines.append([x1, y1, x2, y2])\n",
        "                elif slope > 0.3 and x1 > img_center:  # 오른쪽 차선 (양의 기울기)\n",
        "                    right_lines.append([x1, y1, x2, y2])\n",
        "\n",
        "    # 차선 연결 함수\n",
        "    def connect_lane_segments(lines, frame_height):\n",
        "        if not lines:\n",
        "            return None\n",
        "\n",
        "        # 모든 점들을 수집\n",
        "        points = []\n",
        "        for x1, y1, x2, y2 in lines:\n",
        "            points.extend([(x1, y1), (x2, y2)])\n",
        "\n",
        "        if len(points) < 2:\n",
        "            return None\n",
        "\n",
        "        # 최소자승법으로 직선 피팅\n",
        "        points = np.array(points)\n",
        "        x_coords = points[:, 0]\n",
        "        y_coords = points[:, 1]\n",
        "\n",
        "        # 1차 다항식 피팅\n",
        "        coeffs = np.polyfit(y_coords, x_coords, 1)\n",
        "\n",
        "        # 화면 상하단에서의 x 좌표 계산\n",
        "        y_top = frame_height // 2\n",
        "        y_bottom = frame_height\n",
        "        x_top = int(coeffs[0] * y_top + coeffs[1])\n",
        "        x_bottom = int(coeffs[0] * y_bottom + coeffs[1])\n",
        "\n",
        "        return [x_top, y_top, x_bottom, y_bottom]\n",
        "\n",
        "    # 좌측/우측 차선 연결\n",
        "    left_lane = connect_lane_segments(left_lines, frame.shape[0])\n",
        "    right_lane = connect_lane_segments(right_lines, frame.shape[0])\n",
        "\n",
        "    # 연결된 차선 그리기\n",
        "    if left_lane:\n",
        "        cv2.line(lane_frame, (left_lane[0], left_lane[1]),\n",
        "                (left_lane[2], left_lane[3]), (0, 255, 0), 5)  # 녹색 왼쪽 차선\n",
        "        cv2.putText(lane_frame, \"LEFT\", (left_lane[0]-30, left_lane[1]-10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "    if right_lane:\n",
        "        cv2.line(lane_frame, (right_lane[0], right_lane[1]),\n",
        "                (right_lane[2], right_lane[3]), (255, 0, 0), 5)  # 파란색 오른쪽 차선\n",
        "        cv2.putText(lane_frame, \"RIGHT\", (right_lane[0]+10, right_lane[1]-10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "\n",
        "    # ROI 영역을 시각화 (사다리꼴 모양 표시)\n",
        "    roi_points = np.array([\n",
        "        [frame.shape[1]//5, frame.shape[0]],            # 왼쪽 아래 (20%)\n",
        "        [frame.shape[1]*9//20, frame.shape[0]*3//5],    # 왼쪽 위 (45%)\n",
        "        [frame.shape[1]*13//20, frame.shape[0]*3//5],   # 오른쪽 위 (65%)\n",
        "        [frame.shape[1]*19//20, frame.shape[0]]         # 오른쪽 아래 (95%)\n",
        "    ], np.int32)\n",
        "\n",
        "    cv2.polylines(result_frame, [roi_points], True, (255, 0, 0), 2)  # 파란색 사다리꼴\n",
        "\n",
        "    # 매 30프레임마다 결과 출력\n",
        "    if frame_count % 10 == 0:\n",
        "        # 영어 라벨 추가\n",
        "        cv2.putText(result_frame, \"Original + ROI\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        edge_display = cv2.cvtColor(masked_edges, cv2.COLOR_GRAY2BGR)\n",
        "        cv2.putText(edge_display, \"Canny Edge Detection\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        cv2.putText(lane_frame, \"Lane Detection Result\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        # 3개 화면을 나란히 표시\n",
        "        combined = np.hstack((result_frame, edge_display, lane_frame))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 후 종료 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "# 자원 해제\n",
        "cap.release()\n",
        "print(\"차선 검출 처리 완료!\")"
      ],
      "metadata": {
        "id": "tCbZToX1A2km"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}